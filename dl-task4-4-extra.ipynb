{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":396802,"sourceType":"datasetVersion","datasetId":175990}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-20T17:58:46.590614Z","iopub.execute_input":"2025-02-20T17:58:46.590933Z","iopub.status.idle":"2025-02-20T17:58:46.594605Z","shell.execute_reply.started":"2025-02-20T17:58:46.590904Z","shell.execute_reply":"2025-02-20T17:58:46.593629Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2 as cv\nimport re\nimport requests\n\nfrom sklearn.metrics import confusion_matrix,  multilabel_confusion_matrix\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\nfrom keras.layers import BatchNormalization, Activation, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T17:58:46.609219Z","iopub.execute_input":"2025-02-20T17:58:46.609447Z","iopub.status.idle":"2025-02-20T17:58:59.251600Z","shell.execute_reply.started":"2025-02-20T17:58:46.609427Z","shell.execute_reply":"2025-02-20T17:58:59.250593Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv('/kaggle/input/fashion-product-images-small/styles.csv', usecols = ['id', 'gender', 'baseColour']) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:12:38.282428Z","iopub.execute_input":"2025-02-20T19:12:38.282719Z","iopub.status.idle":"2025-02-20T19:12:38.327889Z","shell.execute_reply.started":"2025-02-20T19:12:38.282695Z","shell.execute_reply":"2025-02-20T19:12:38.327115Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:12:39.107981Z","iopub.execute_input":"2025-02-20T19:12:39.108331Z","iopub.status.idle":"2025-02-20T19:12:39.116320Z","shell.execute_reply.started":"2025-02-20T19:12:39.108302Z","shell.execute_reply":"2025-02-20T19:12:39.115551Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"      id gender baseColour\n0  15970    Men  Navy Blue\n1  39386    Men       Blue\n2  59263  Women     Silver\n3  21379    Men      Black\n4  53759    Men       Grey","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gender</th>\n      <th>baseColour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15970</td>\n      <td>Men</td>\n      <td>Navy Blue</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39386</td>\n      <td>Men</td>\n      <td>Blue</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>59263</td>\n      <td>Women</td>\n      <td>Silver</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21379</td>\n      <td>Men</td>\n      <td>Black</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>53759</td>\n      <td>Men</td>\n      <td>Grey</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:12:40.095619Z","iopub.execute_input":"2025-02-20T19:12:40.095916Z","iopub.status.idle":"2025-02-20T19:12:40.112420Z","shell.execute_reply.started":"2025-02-20T19:12:40.095891Z","shell.execute_reply":"2025-02-20T19:12:40.111313Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 44446 entries, 0 to 44445\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   id          44446 non-null  int64 \n 1   gender      44446 non-null  object\n 2   baseColour  44431 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 1.0+ MB\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"data = data.dropna()\ndata.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:12:40.451963Z","iopub.execute_input":"2025-02-20T19:12:40.452296Z","iopub.status.idle":"2025-02-20T19:12:40.476422Z","shell.execute_reply.started":"2025-02-20T19:12:40.452270Z","shell.execute_reply":"2025-02-20T19:12:40.475466Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 44431 entries, 0 to 44445\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   id          44431 non-null  int64 \n 1   gender      44431 non-null  object\n 2   baseColour  44431 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 1.4+ MB\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"data_encoded = pd.get_dummies(data, columns=['gender', 'baseColour'], dtype = 'int')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:12:43.634431Z","iopub.execute_input":"2025-02-20T19:12:43.634718Z","iopub.status.idle":"2025-02-20T19:12:43.655573Z","shell.execute_reply.started":"2025-02-20T19:12:43.634695Z","shell.execute_reply":"2025-02-20T19:12:43.654928Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"data_encoded.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:12:45.135551Z","iopub.execute_input":"2025-02-20T19:12:45.135846Z","iopub.status.idle":"2025-02-20T19:12:45.150348Z","shell.execute_reply.started":"2025-02-20T19:12:45.135821Z","shell.execute_reply":"2025-02-20T19:12:45.149608Z"}},"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"      id  gender_Boys  gender_Girls  gender_Men  gender_Unisex  gender_Women  \\\n0  15970            0             0           1              0             0   \n1  39386            0             0           1              0             0   \n2  59263            0             0           0              0             1   \n3  21379            0             0           1              0             0   \n4  53759            0             0           1              0             0   \n\n   baseColour_Beige  baseColour_Black  baseColour_Blue  baseColour_Bronze  \\\n0                 0                 0                0                  0   \n1                 0                 0                1                  0   \n2                 0                 0                0                  0   \n3                 0                 1                0                  0   \n4                 0                 0                0                  0   \n\n   ...  baseColour_Sea Green  baseColour_Silver  baseColour_Skin  \\\n0  ...                     0                  0                0   \n1  ...                     0                  0                0   \n2  ...                     0                  1                0   \n3  ...                     0                  0                0   \n4  ...                     0                  0                0   \n\n   baseColour_Steel  baseColour_Tan  baseColour_Taupe  baseColour_Teal  \\\n0                 0               0                 0                0   \n1                 0               0                 0                0   \n2                 0               0                 0                0   \n3                 0               0                 0                0   \n4                 0               0                 0                0   \n\n   baseColour_Turquoise Blue  baseColour_White  baseColour_Yellow  \n0                          0                 0                  0  \n1                          0                 0                  0  \n2                          0                 0                  0  \n3                          0                 0                  0  \n4                          0                 0                  0  \n\n[5 rows x 52 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gender_Boys</th>\n      <th>gender_Girls</th>\n      <th>gender_Men</th>\n      <th>gender_Unisex</th>\n      <th>gender_Women</th>\n      <th>baseColour_Beige</th>\n      <th>baseColour_Black</th>\n      <th>baseColour_Blue</th>\n      <th>baseColour_Bronze</th>\n      <th>...</th>\n      <th>baseColour_Sea Green</th>\n      <th>baseColour_Silver</th>\n      <th>baseColour_Skin</th>\n      <th>baseColour_Steel</th>\n      <th>baseColour_Tan</th>\n      <th>baseColour_Taupe</th>\n      <th>baseColour_Teal</th>\n      <th>baseColour_Turquoise Blue</th>\n      <th>baseColour_White</th>\n      <th>baseColour_Yellow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15970</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39386</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>59263</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21379</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>53759</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 52 columns</p>\n</div>"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"data_encoded.shape[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:12:47.435175Z","iopub.execute_input":"2025-02-20T19:12:47.435451Z","iopub.status.idle":"2025-02-20T19:12:47.440304Z","shell.execute_reply.started":"2025-02-20T19:12:47.435428Z","shell.execute_reply":"2025-02-20T19:12:47.439524Z"}},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"44431"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"data_encoded.shape[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:12:47.530184Z","iopub.execute_input":"2025-02-20T19:12:47.530390Z","iopub.status.idle":"2025-02-20T19:12:47.534938Z","shell.execute_reply.started":"2025-02-20T19:12:47.530371Z","shell.execute_reply":"2025-02-20T19:12:47.534105Z"}},"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"52"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"from tqdm import tqdm\nfrom keras.preprocessing import image\nfrom tensorflow.keras.applications import ResNet152V2, InceptionResNetV2, EfficientNetV2S\nfrom tensorflow.keras.applications.efficientnet_v2 import preprocess_input as efficientnet_preprocess\nfrom sklearn.model_selection import train_test_split\nimport os\n\n\ndataset_path = '/kaggle/input/fashion-product-images-small/images/'\ntarget_size = (224, 224)\nbatch_size = 32 \n\n\ndata_encoded['filename'] = data_encoded['id'].astype(str) + '.jpg'\ny_columns = data_encoded.columns.drop(['id', 'filename'])  \n\n\ntrain_df, test_df = train_test_split(data_encoded, test_size=0.3, random_state=20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:12:50.815736Z","iopub.execute_input":"2025-02-20T19:12:50.816018Z","iopub.status.idle":"2025-02-20T19:12:50.855601Z","shell.execute_reply.started":"2025-02-20T19:12:50.815996Z","shell.execute_reply":"2025-02-20T19:12:50.854727Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"y_columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:12:51.249778Z","iopub.execute_input":"2025-02-20T19:12:51.250208Z","iopub.status.idle":"2025-02-20T19:12:51.257410Z","shell.execute_reply.started":"2025-02-20T19:12:51.250163Z","shell.execute_reply":"2025-02-20T19:12:51.256288Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"Index(['gender_Boys', 'gender_Girls', 'gender_Men', 'gender_Unisex',\n       'gender_Women', 'baseColour_Beige', 'baseColour_Black',\n       'baseColour_Blue', 'baseColour_Bronze', 'baseColour_Brown',\n       'baseColour_Burgundy', 'baseColour_Charcoal', 'baseColour_Coffee Brown',\n       'baseColour_Copper', 'baseColour_Cream', 'baseColour_Fluorescent Green',\n       'baseColour_Gold', 'baseColour_Green', 'baseColour_Grey',\n       'baseColour_Grey Melange', 'baseColour_Khaki', 'baseColour_Lavender',\n       'baseColour_Lime Green', 'baseColour_Magenta', 'baseColour_Maroon',\n       'baseColour_Mauve', 'baseColour_Metallic', 'baseColour_Multi',\n       'baseColour_Mushroom Brown', 'baseColour_Mustard',\n       'baseColour_Navy Blue', 'baseColour_Nude', 'baseColour_Off White',\n       'baseColour_Olive', 'baseColour_Orange', 'baseColour_Peach',\n       'baseColour_Pink', 'baseColour_Purple', 'baseColour_Red',\n       'baseColour_Rose', 'baseColour_Rust', 'baseColour_Sea Green',\n       'baseColour_Silver', 'baseColour_Skin', 'baseColour_Steel',\n       'baseColour_Tan', 'baseColour_Taupe', 'baseColour_Teal',\n       'baseColour_Turquoise Blue', 'baseColour_White', 'baseColour_Yellow'],\n      dtype='object')"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_gen = ImageDataGenerator(\n    preprocessing_function=efficientnet_preprocess,\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True\n)\n\ntest_gen = ImageDataGenerator(\n    preprocessing_function=efficientnet_preprocess\n)\n\ntrain_generator = train_gen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=dataset_path,\n    x_col='filename',\n    y_col=list(y_columns),\n    target_size=target_size,\n    class_mode='raw',  \n    batch_size=batch_size,\n    shuffle=True\n)\n\n\ntest_generator = test_gen.flow_from_dataframe(\n    dataframe=test_df,\n    directory=dataset_path,\n    x_col='filename',\n    y_col=list(y_columns),\n    target_size=target_size,\n    class_mode='raw',\n    batch_size=batch_size,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:12:53.005169Z","iopub.execute_input":"2025-02-20T19:12:53.005452Z","iopub.status.idle":"2025-02-20T19:13:17.200141Z","shell.execute_reply.started":"2025-02-20T19:12:53.005428Z","shell.execute_reply":"2025-02-20T19:13:17.199399Z"}},"outputs":[{"name":"stdout","text":"Found 31097 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 4 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 13329 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"\nimport tensorflow as tf\nfrom tensorflow.keras.applications import ResNet152V2, InceptionResNetV2, EfficientNetV2S\nfrom tensorflow.keras.applications.efficientnet_v2 import preprocess_input as efficientnet_preprocess\nfrom tensorflow.keras import layers, models\n\ndef efficeint_builder(): \n  base_model = EfficientNetV2S(\n      weights='imagenet',\n      include_top=False,\n      input_shape=target_size + (3,),\n      pooling = 'avg'\n  )\n  base_model.trainable = False\n\n  model = models.Sequential([\n      base_model,\n      layers.Dense(128, activation='relu'),  \n      layers.Dropout(0.3),\n      layers.Dense(51, activation='sigmoid')\n  ])\n\n  model.compile(\n      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n      loss='binary_crossentropy',\n      metrics=['accuracy']\n  )\n\n  return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:13:17.201514Z","iopub.execute_input":"2025-02-20T19:13:17.201870Z","iopub.status.idle":"2025-02-20T19:13:17.206998Z","shell.execute_reply.started":"2025-02-20T19:13:17.201845Z","shell.execute_reply":"2025-02-20T19:13:17.206222Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"model = efficeint_builder()\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:13:17.208547Z","iopub.execute_input":"2025-02-20T19:13:17.208759Z","iopub.status.idle":"2025-02-20T19:13:19.422451Z","shell.execute_reply.started":"2025-02-20T19:13:17.208738Z","shell.execute_reply":"2025-02-20T19:13:19.421742Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ efficientnetv2-s (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │      \u001b[38;5;34m20,331,360\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m163,968\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)                  │           \u001b[38;5;34m6,579\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ efficientnetv2-s (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">20,331,360</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,579</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,501,907\u001b[0m (78.21 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,501,907</span> (78.21 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m170,547\u001b[0m (666.20 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,547</span> (666.20 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,331,360\u001b[0m (77.56 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,331,360</span> (77.56 MB)\n</pre>\n"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True , verbose=1)]\n\nhistory = model.fit(\n    train_generator,\n    validation_data=test_generator,\n    epochs=10,\n    verbose = 1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:13:19.423296Z","iopub.execute_input":"2025-02-20T19:13:19.423579Z","iopub.status.idle":"2025-02-20T20:16:31.719350Z","shell.execute_reply.started":"2025-02-20T19:13:19.423556Z","shell.execute_reply":"2025-02-20T20:16:31.718480Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 414ms/step - accuracy: 0.6533 - loss: 0.1334 - val_accuracy: 0.8091 - val_loss: 0.0653\nEpoch 2/10\n\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 380ms/step - accuracy: 0.7718 - loss: 0.0692 - val_accuracy: 0.7977 - val_loss: 0.0599\nEpoch 3/10\n\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 380ms/step - accuracy: 0.7777 - loss: 0.0646 - val_accuracy: 0.8008 - val_loss: 0.0574\nEpoch 4/10\n\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 378ms/step - accuracy: 0.7780 - loss: 0.0622 - val_accuracy: 0.8229 - val_loss: 0.0567\nEpoch 5/10\n\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 382ms/step - accuracy: 0.7849 - loss: 0.0606 - val_accuracy: 0.8097 - val_loss: 0.0552\nEpoch 6/10\n\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 382ms/step - accuracy: 0.7846 - loss: 0.0587 - val_accuracy: 0.8177 - val_loss: 0.0548\nEpoch 7/10\n\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 382ms/step - accuracy: 0.7951 - loss: 0.0578 - val_accuracy: 0.8125 - val_loss: 0.0541\nEpoch 8/10\n\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 380ms/step - accuracy: 0.7923 - loss: 0.0570 - val_accuracy: 0.8286 - val_loss: 0.0533\nEpoch 9/10\n\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 376ms/step - accuracy: 0.7966 - loss: 0.0568 - val_accuracy: 0.8172 - val_loss: 0.0530\nEpoch 10/10\n\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 380ms/step - accuracy: 0.7981 - loss: 0.0557 - val_accuracy: 0.8208 - val_loss: 0.0522\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"# fine tuning on a subset\nsubset_size = int(0.4 * len(data_encoded))\n\n\nsubset_df = data_encoded.sample(n=subset_size, random_state=42)\n\ntrain_df, test_df = train_test_split(subset_df, test_size=0.1, random_state=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:17:25.182362Z","iopub.execute_input":"2025-02-20T20:17:25.182675Z","iopub.status.idle":"2025-02-20T20:17:25.203633Z","shell.execute_reply.started":"2025-02-20T20:17:25.182647Z","shell.execute_reply":"2025-02-20T20:17:25.202789Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_gen = ImageDataGenerator(\n    preprocessing_function=efficientnet_preprocess,\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True\n)\n\ntest_gen = ImageDataGenerator(\n    preprocessing_function=efficientnet_preprocess\n)\n\ntrain_generator = train_gen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=dataset_path,\n    x_col='filename',\n    y_col=list(y_columns),\n    target_size=target_size,\n    class_mode='raw',  \n    batch_size=batch_size,\n    shuffle=True\n)\n\n\ntest_generator = test_gen.flow_from_dataframe(\n    dataframe=test_df,\n    directory=dataset_path,\n    x_col='filename',\n    y_col=list(y_columns),\n    target_size=target_size,\n    class_mode='raw',\n    batch_size=batch_size,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:17:26.233704Z","iopub.execute_input":"2025-02-20T20:17:26.233988Z","iopub.status.idle":"2025-02-20T20:17:29.136289Z","shell.execute_reply.started":"2025-02-20T20:17:26.233965Z","shell.execute_reply":"2025-02-20T20:17:29.135310Z"}},"outputs":[{"name":"stdout","text":"Found 15992 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 2 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 1778 validated image filenames.\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"base_model = model.layers[0]  \nbase_model.trainable = True  \n\nfor layer in base_model.layers[:int(len(base_model.layers)*0.8)]:  \n    layer.trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:17:35.211010Z","iopub.execute_input":"2025-02-20T20:17:35.211308Z","iopub.status.idle":"2025-02-20T20:17:35.229091Z","shell.execute_reply.started":"2025-02-20T20:17:35.211285Z","shell.execute_reply":"2025-02-20T20:17:35.228287Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"  model.compile(\n      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n      loss='binary_crossentropy',\n      metrics=['accuracy']\n  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:17:39.037680Z","iopub.execute_input":"2025-02-20T20:17:39.037993Z","iopub.status.idle":"2025-02-20T20:17:39.047537Z","shell.execute_reply.started":"2025-02-20T20:17:39.037968Z","shell.execute_reply":"2025-02-20T20:17:39.046729Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"history_2 = model.fit(\n    train_generator,\n    validation_data=test_generator,\n    epochs=10,\n    verbose = 1,\n    callbacks = callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:17:41.855865Z","iopub.execute_input":"2025-02-20T20:17:41.856167Z","iopub.status.idle":"2025-02-20T20:49:20.418250Z","shell.execute_reply.started":"2025-02-20T20:17:41.856142Z","shell.execute_reply":"2025-02-20T20:49:20.417503Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 450ms/step - accuracy: 0.7643 - loss: 0.0767 - val_accuracy: 0.7998 - val_loss: 0.0534\nEpoch 2/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 350ms/step - accuracy: 0.7739 - loss: 0.0614 - val_accuracy: 0.8127 - val_loss: 0.0514\nEpoch 3/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 356ms/step - accuracy: 0.7746 - loss: 0.0594 - val_accuracy: 0.8060 - val_loss: 0.0500\nEpoch 4/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 352ms/step - accuracy: 0.7824 - loss: 0.0567 - val_accuracy: 0.8110 - val_loss: 0.0491\nEpoch 5/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 354ms/step - accuracy: 0.7883 - loss: 0.0554 - val_accuracy: 0.8150 - val_loss: 0.0485\nEpoch 6/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 352ms/step - accuracy: 0.7921 - loss: 0.0539 - val_accuracy: 0.8245 - val_loss: 0.0479\nEpoch 7/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 355ms/step - accuracy: 0.7937 - loss: 0.0533 - val_accuracy: 0.8155 - val_loss: 0.0473\nEpoch 8/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 353ms/step - accuracy: 0.7908 - loss: 0.0524 - val_accuracy: 0.8150 - val_loss: 0.0468\nEpoch 9/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 351ms/step - accuracy: 0.8007 - loss: 0.0510 - val_accuracy: 0.8138 - val_loss: 0.0464\nEpoch 10/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 351ms/step - accuracy: 0.8083 - loss: 0.0503 - val_accuracy: 0.8161 - val_loss: 0.0462\nRestoring model weights from the end of the best epoch: 10.\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"model.save('fashion_v2.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:49:20.419592Z","iopub.execute_input":"2025-02-20T20:49:20.419864Z","iopub.status.idle":"2025-02-20T20:49:21.867614Z","shell.execute_reply.started":"2025-02-20T20:49:20.419840Z","shell.execute_reply":"2025-02-20T20:49:21.866582Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"label_names = list(y_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T19:09:47.075108Z","iopub.status.idle":"2025-02-20T19:09:47.075437Z","shell.execute_reply":"2025-02-20T19:09:47.075316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = '/kaggle/input/fashion-product-images-small/images/14856.jpg'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T18:48:11.359228Z","iopub.execute_input":"2025-02-20T18:48:11.359542Z","iopub.status.idle":"2025-02-20T18:48:11.363115Z","shell.execute_reply.started":"2025-02-20T18:48:11.359512Z","shell.execute_reply":"2025-02-20T18:48:11.362121Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n\n\n\ndef predict_top_labels(model, image_path, target_size=(224, 224)):\n    image = load_img(image_path, target_size=target_size)\n    image_array = img_to_array(image)\n    image_array = np.expand_dims(image_array, axis=0)\n    image_array = efficientnet_preprocess(image_array)\n\n    predictions = model.predict(image_array)[0]\n    \n    \n    gender_predictions = [(label, predictions[i])\n                          for i, label in enumerate(label_names)\n                          if label.startswith(\"gender_\")]\n    top_gender = max(gender_predictions, key=lambda x: x[1]) if gender_predictions else None\n    \n   \n    colour_predictions = [(label, predictions[i])\n                          for i, label in enumerate(label_names)\n                          if label.startswith(\"baseColour_\")]\n    top_colour = max(colour_predictions, key=lambda x: x[1]) if colour_predictions else None\n    \n    return top_gender, top_colour","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T18:44:03.101424Z","iopub.execute_input":"2025-02-20T18:44:03.101712Z","iopub.status.idle":"2025-02-20T18:44:03.107575Z","shell.execute_reply.started":"2025-02-20T18:44:03.101689Z","shell.execute_reply":"2025-02-20T18:44:03.106660Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"print(predict_top_labels(model, image_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T18:48:13.057204Z","iopub.execute_input":"2025-02-20T18:48:13.057517Z","iopub.status.idle":"2025-02-20T18:48:13.134755Z","shell.execute_reply.started":"2025-02-20T18:48:13.057487Z","shell.execute_reply":"2025-02-20T18:48:13.134126Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n(('gender_Women', 0.94500405), ('baseColour_Brown', 0.30091295))\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}